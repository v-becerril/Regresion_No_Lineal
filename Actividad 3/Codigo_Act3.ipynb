{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fea35251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as special\n",
    "from scipy.optimize import curve_fit\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f6b8dd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Mexico_Limpio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fc8e9d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos las bases de datos\n",
    "limpio = pd.read_csv('Mexico_Limpio.csv')\n",
    "original = pd.read_csv('Original_Mexico.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7262b88",
   "metadata": {},
   "source": [
    "VARIABLES ELEGIDAS\n",
    "Mexico_Limpio = 'host_is_superhost', 'accommodates', 'bathrooms', 'bedrooms', 'beds','room_type' \n",
    "Original_Mexico = 'host_response_time', 'host_verifications', 'instant_bookable', 'host_since'  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d98877",
   "metadata": {},
   "source": [
    "Limpia de datos y conversción a tipo dicotómicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8bb7c9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>room_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Entire home/apt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Entire home/apt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Entire home/apt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Entire home/apt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Entire home/apt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   host_is_superhost  accommodates  bathrooms  bedrooms  beds        room_type\n",
       "0                0.0             2       1.00       1.0   1.0  Entire home/apt\n",
       "1                0.0             7       2.25       3.5   3.5  Entire home/apt\n",
       "2                0.0             2       1.00       1.0   1.0  Entire home/apt\n",
       "3                0.0             4       1.00       2.0   2.0  Entire home/apt\n",
       "4                1.0             2       1.00       1.0   1.0  Entire home/apt"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elegidas = limpio[['host_is_superhost', 'accommodates', 'bathrooms', 'bedrooms', 'beds','room_type']]\n",
    "elegidas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cc76c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de valores únicos de las columnas de interés\n",
      "host_is_superhost: [0.        1.        0.3864308]\n",
      "accommodates: [2 7 4 3 1 5 6]\n",
      "bathrooms: [1.         2.25       1.45038927 1.5        2.         0.5\n",
      " 0.25      ]\n",
      "bedrooms: [1.        3.5       2.        0.        1.5550889 3.       ]\n",
      "beds: [1.         3.5        2.         1.95321156 3.         0.        ]\n",
      "room_type: ['Entire home/apt' 'Private room' 'Hotel room' 'Shared room']\n"
     ]
    }
   ],
   "source": [
    "print('Lista de valores únicos de las columnas de interés')\n",
    "\n",
    "#La columna 'host_is_superhost' nos indica la capacidad de huéspedes\n",
    "print('host_is_superhost:',limpio['host_is_superhost'].unique())\n",
    "\n",
    "#La columna 'accommodates' nos indica la capacidad de huéspedes\n",
    "print('accommodates:',limpio['accommodates'].unique())\n",
    "\n",
    "#La columna 'bathrooms' nos indica el número de baños\n",
    "print('bathrooms:', limpio['bathrooms'].unique())\n",
    "\n",
    "#La columna 'bedrooms' nos indica el número de habitaciones\n",
    "print('bedrooms:', limpio['bedrooms'].unique())\n",
    "\n",
    "#La columna 'beds' nos indica el número de camas\n",
    "print('beds:', limpio['beds'].unique())\n",
    "\n",
    "#La columna 'room_type' nos indica el tipo de alojamiento \n",
    "print('room_type:', limpio['room_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7a0d326a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------host_is_superhost: ['Es Superhost' 'No es Superhost']\n",
      "-------accommodates: ['Alojamiento para Parejas/Individual' 'Alojamiento para Familias/Grupos']\n",
      "-------bathrooms: ['Uno o más baños completos' 'Menos de un baño completo']\n",
      "-------bedrooms: ['Dos o menos de dos cuartos' 'Más de dos cuartos']\n",
      "-------beds: ['Dos o menos de dos camas' 'Más de dos camas']\n",
      "-------room_type : ['Alojamiento Completo' 'Alojamiento Parcial']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\3467536860.py:9: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  limpio['host_is_superhost'] = limpio['host_is_superhost'].fillna(method='ffill')\n",
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\3467536860.py:11: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  limpio['host_is_superhost'] = limpio['host_is_superhost'].fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "#Tratamos columna 'host_is_superhost'\n",
    "#Pasamos la columna a cadena de texto\n",
    "limpio['host_is_superhost'] = limpio['host_is_superhost'].astype(str)\n",
    "\n",
    "#Cambiamos los que tienen el valor de '0.386430796' a valores invalidos para susittuirlos\n",
    "limpio['host_is_superhost'] = limpio['host_is_superhost'].replace({'0.386430796': np.nan})\n",
    "\n",
    "#Rellena los NaN usando el valor anterior (Forward Fill)\n",
    "limpio['host_is_superhost'] = limpio['host_is_superhost'].fillna(method='ffill')\n",
    "#Rellena los NaN usando el valor posterior (Backward Fill)\n",
    "limpio['host_is_superhost'] = limpio['host_is_superhost'].fillna(method='bfill')\n",
    "\n",
    "limpio['host_is_superhost'] = limpio['host_is_superhost'].replace({'0.0': 'Es Superhost', '1.0':'No es Superhost'}) \n",
    "#Verificamos valores unicos\n",
    "print('-------host_is_superhost:',limpio['host_is_superhost'].unique())\n",
    "\n",
    "\n",
    "#Tratamos columna 'accommodates'\n",
    "#Pasamos la columna a cadena de texto\n",
    "limpio['accommodates'] = limpio['accommodates'].astype(str)\n",
    "limpio['accommodates'] = limpio['accommodates'].replace({'1': 'Alojamiento para Parejas/Individual', '2':'Alojamiento para Parejas/Individual',\n",
    "                                                         '3': 'Alojamiento para Familias/Grupos', '4': 'Alojamiento para Familias/Grupos', '5': 'Alojamiento para Familias/Grupos', \n",
    "                                                         '6': 'Alojamiento para Familias/Grupos', '7': 'Alojamiento para Familias/Grupos' }) \n",
    "#Verificamos valores únicos\n",
    "print('-------accommodates:',limpio['accommodates'].unique())\n",
    "\n",
    "#Tratamos columna 'bathrooms'\n",
    "#Pasamos la columna a cadena de texto\n",
    "limpio['bathrooms'] = limpio['bathrooms'].astype(str)\n",
    "limpio['bathrooms'] = limpio['bathrooms'].replace({'0.5': 'Menos de un baño completo', '0.25':'Menos de un baño completo',\n",
    "                                                    '1.0': 'Uno o más baños completos', '2.0': 'Uno o más baños completos', '1.5': 'Uno o más baños completos', \n",
    "                                                    '1.450389273': 'Uno o más baños completos', '2.25': 'Uno o más baños completos' }) \n",
    "#Verificamos valores únicos\n",
    "print('-------bathrooms:',limpio['bathrooms'].unique())\n",
    "\n",
    "\n",
    "#Tratamos columna 'bedrooms'\n",
    "#Pasamos la columna a cadena de texto\n",
    "limpio['bedrooms'] = limpio['bedrooms'].astype(str)\n",
    "limpio['bedrooms'] = limpio['bedrooms'].replace({'0.0': 'Dos o menos de dos cuartos', '2.0':'Dos o menos de dos cuartos',\n",
    "                                                    '1.0': 'Dos o menos de dos cuartos', '3.0': 'Más de dos cuartos', '3.5': 'Más de dos cuartos', \n",
    "                                                    '1.555088904': 'Dos o menos de dos cuartos'}) \n",
    "#Verificamos valores únicos\n",
    "print('-------bedrooms:',limpio['bedrooms'].unique())\n",
    "\n",
    "#Tratamos columna 'beds'\n",
    "#Pasamos la columna a cadena de texto\n",
    "limpio['beds'] = limpio['beds'].astype(str)\n",
    "limpio['beds'] = limpio['beds'].replace({'0.0': 'Dos o menos de dos camas', '2.0':'Dos o menos de dos camas',\n",
    "                                                    '1.0': 'Dos o menos de dos camas', '3.0': 'Más de dos camas', '3.5': 'Más de dos camas', \n",
    "                                                    '1.953211565': 'Dos o menos de dos camas'}) \n",
    "#Verificamos valores únicos\n",
    "print('-------beds:',limpio['beds'].unique())\n",
    "\n",
    "#Tratamos columna 'room_type'\n",
    "#Pasamos la columna a cadena de texto\n",
    "limpio['room_type'] = limpio['room_type'].astype(str)\n",
    "limpio['room_type'] = limpio['room_type'].replace({'Entire home/apt': 'Alojamiento Completo', 'Hotel room': 'Alojamiento Completo',\n",
    "                                                   'Private room': 'Alojamiento Parcial', 'Shared room': 'Alojamiento Parcial'}) \n",
    "#Verificamos valores únicos\n",
    "print('-------room_type :',limpio['room_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a8335cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>host_verifications</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>host_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>['email', 'phone', 'work_email']</td>\n",
       "      <td>f</td>\n",
       "      <td>28/06/2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>within an hour</td>\n",
       "      <td>['email', 'phone', 'work_email']</td>\n",
       "      <td>f</td>\n",
       "      <td>09/08/2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>within a few hours</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>f</td>\n",
       "      <td>19/10/2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>within a few hours</td>\n",
       "      <td>['email', 'phone']</td>\n",
       "      <td>f</td>\n",
       "      <td>04/01/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>within a few hours</td>\n",
       "      <td>['email', 'phone', 'work_email']</td>\n",
       "      <td>f</td>\n",
       "      <td>24/08/2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   host_response_time                host_verifications instant_bookable  \\\n",
       "0                 NaN  ['email', 'phone', 'work_email']                f   \n",
       "1      within an hour  ['email', 'phone', 'work_email']                f   \n",
       "2  within a few hours                ['email', 'phone']                f   \n",
       "3  within a few hours                ['email', 'phone']                f   \n",
       "4  within a few hours  ['email', 'phone', 'work_email']                f   \n",
       "\n",
       "   host_since  \n",
       "0  28/06/2010  \n",
       "1  09/08/2010  \n",
       "2  19/10/2010  \n",
       "3  04/01/2011  \n",
       "4  24/08/2010  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Agarramos la variables objetivo que necesitamos de la base original, las tratamos y agregamos a la base limpia\n",
    "cambio = original[['host_response_time', 'host_verifications', 'instant_bookable', 'host_since']]\n",
    "cambio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "cb4db60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(914)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#La columna 'host_since' nos habla de que fecha es dado de alta en la plataforma y es anfitrión \n",
    "cambio['host_since'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "38bf59c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores nulos: 0\n",
      "La fecha de alta de anfitrión que más se repite es: 2023-01-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\2929194693.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  cambio['host_since'] = cambio['host_since'].fillna(method='ffill')\n",
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\2929194693.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cambio['host_since'] = cambio['host_since'].fillna(method='ffill')\n",
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\2929194693.py:5: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  cambio['host_since'] = cambio['host_since'].fillna(method='bfill')\n",
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\2929194693.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cambio['host_since'] = cambio['host_since'].fillna(method='bfill')\n",
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\2929194693.py:10: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  cambio['host_since'] = pd.to_datetime(cambio['host_since'])\n",
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\2929194693.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cambio['host_since'] = pd.to_datetime(cambio['host_since'])\n"
     ]
    }
   ],
   "source": [
    "#Rellena los NaN usando el valor anterior (Forward Fill)\n",
    "cambio['host_since'] = cambio['host_since'].fillna(method='ffill')\n",
    "\n",
    "#Rellena los NaN usando el valor posterior (Backward Fill)\n",
    "cambio['host_since'] = cambio['host_since'].fillna(method='bfill')\n",
    "\n",
    "#Verifcamos trata de NAN's\n",
    "print('Número de valores nulos:', cambio['host_since'].isnull().sum())\n",
    "#Transformamos a tipo date\n",
    "cambio['host_since'] = pd.to_datetime(cambio['host_since'])\n",
    "\n",
    "#Conseguimos fecha 'promedio'\n",
    "fecha_mas_repetida = cambio['host_since'].mode().iloc[0]\n",
    "print(\"La fecha de alta de anfitrión que más se repite es:\", fecha_mas_repetida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8129e5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los valores unicos de la columna agrupada:  ['Antes del 30/01/2023' 'Después del 30/01/2023']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\260167155.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cambio['host_since_agrupada'] = np.where(host_since_dt < FECHA_CORTE, 'Antes del 30/01/2023','Después del 30/01/2023')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definimos fecha de partido\n",
    "FECHA_CORTE = pd.to_datetime('2023-01-30')\n",
    "\n",
    "# Convertimos la columna de texto 'host_since' a datetime, especificando el formato\n",
    "host_since_dt = pd.to_datetime(cambio['host_since'], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "# #Hacemos el ajuste de las fechas\n",
    "cambio['host_since_agrupada'] = np.where(host_since_dt < FECHA_CORTE, 'Antes del 30/01/2023','Después del 30/01/2023')\n",
    "\n",
    "# #Verificamos cambios\n",
    "print('Los valores unicos de la columna agrupada: ', cambio['host_since_agrupada'].unique())\n",
    "#Verificamos valores nulos después de todas las modificaciones\n",
    "cambio['host_since'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f07c8306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de valores únicos de la columna: [\"['email', 'phone', 'work_email']\" \"['email', 'phone']\" \"['phone']\" nan\n",
      " \"['phone', 'work_email']\" \"['email']\" '[]' \"['email', 'work_email']\"\n",
      " \"['work_email']\"]\n"
     ]
    }
   ],
   "source": [
    "#La columna de 'host_verifications' nos indica los métodos de verificación que tiene el anfitrión\n",
    "print('Lista de valores únicos de la columna:',cambio['host_verifications'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e063734f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de valores únicos: ['Más de un método' 'Un método' nan '[]']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\3062924664.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cambio['host_verifications'] = cambio['host_verifications'].replace({\"['email', 'phone', 'work_email']\": 'Más de un método', \"['email', 'phone']\": 'Más de un método', \"['phone', 'work_email']\": 'Más de un método', \"['email', 'work_email']\": 'Más de un método',\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(914)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tratamos columna 'host_verifications'\n",
    "cambio['host_verifications'] = cambio['host_verifications'].replace({\"['email', 'phone', 'work_email']\": 'Más de un método', \"['email', 'phone']\": 'Más de un método', \"['phone', 'work_email']\": 'Más de un método', \"['email', 'work_email']\": 'Más de un método',\n",
    "                                                                    \"['phone']\": 'Un método', \"['email']\": 'Un método', \"['work_email']\": 'Un método' }) \n",
    "#Verificamos cambio y existencia de valores nulos\n",
    "print('Lista de valores únicos:',cambio['host_verifications'].unique())\n",
    "cambio['host_verifications'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0b82f631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\2851848341.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cambio['host_verifications'] = cambio['host_verifications'].replace({'[]': np.nan})\n",
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\2851848341.py:5: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  cambio['host_verifications'] = cambio['host_verifications'].fillna(method='ffill')\n",
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\2851848341.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cambio['host_verifications'] = cambio['host_verifications'].fillna(method='ffill')\n",
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\2851848341.py:8: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  cambio['host_verifications'] = cambio['host_verifications'].fillna(method='bfill')\n",
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\2851848341.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cambio['host_verifications'] = cambio['host_verifications'].fillna(method='bfill')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cambiamos los que tienen [] como si fueran valores invalidos para susittuirlos\n",
    "cambio['host_verifications'] = cambio['host_verifications'].replace({'[]': np.nan})\n",
    "\n",
    "#Rellena los NaN usando el valor anterior (Forward Fill)\n",
    "cambio['host_verifications'] = cambio['host_verifications'].fillna(method='ffill')\n",
    "\n",
    "#Rellena los NaN usando el valor posterior (Backward Fill)\n",
    "cambio['host_verifications'] = cambio['host_verifications'].fillna(method='bfill')\n",
    "\n",
    "#Verificamos que ya no existan valores nulos\n",
    "cambio['host_verifications'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4ccc1a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de valores únicos de la columna: ['f' 't']\n"
     ]
    }
   ],
   "source": [
    "#La columna 'instant_bookable' hace referencia a si el huésped puede reservar automáticamente el anuncio sin la intervención del anfitrión\n",
    "print('Lista de valores únicos de la columna:',cambio['instant_bookable'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "aa357be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de valores únicos: ['No Reserva Automática' 'Reserva Automática']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\654513735.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cambio['instant_bookable'] = cambio['instant_bookable'].replace({'t': 'Reserva Automática', 'f': 'No Reserva Automática'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tratamos columna 'instant_bookable'\n",
    "cambio['instant_bookable'] = cambio['instant_bookable'].replace({'t': 'Reserva Automática', 'f': 'No Reserva Automática'})\n",
    "\n",
    "#Verificamos cambio y existencia de valores nulos\n",
    "print('Lista de valores únicos:',cambio['instant_bookable'].unique())\n",
    "cambio['instant_bookable'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c4e5faee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de valores únicos de la columna: [nan 'within an hour' 'within a few hours' 'a few days or more'\n",
      " 'within a day']\n"
     ]
    }
   ],
   "source": [
    "#La columna 'host_response_time' se refiere a cuanto tarda el anfitrión en contestar\n",
    "print('Lista de valores únicos de la columna:',cambio['host_response_time'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d16a0fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de valores únicos: [nan 'Horas de Respuesta' 'Días de Respuesta']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\3597048255.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cambio['host_response_time'] = cambio['host_response_time'].replace({'within an hour': 'Horas de Respuesta','within a few hours': 'Horas de Respuesta',\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(4686)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tratamos columna 'host_response_time'\n",
    "cambio['host_response_time'] = cambio['host_response_time'].replace({'within an hour': 'Horas de Respuesta','within a few hours': 'Horas de Respuesta', \n",
    "                                                                     'a few days or more': 'Días de Respuesta', 'within a day': 'Días de Respuesta'})\n",
    "\n",
    "#Verificamos cambios\n",
    "print('Lista de valores únicos:',cambio['host_response_time'].unique())\n",
    "#Verificamos valores nulos\n",
    "cambio['host_response_time'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f16b3ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores nulos: 0\n",
      "Lista de valores únicos: ['Horas de Respuesta' 'Días de Respuesta']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\1120293309.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  cambio['host_response_time'] = cambio['host_response_time'].fillna(method='ffill')\n",
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\1120293309.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cambio['host_response_time'] = cambio['host_response_time'].fillna(method='ffill')\n",
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\1120293309.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  cambio['host_response_time'] = cambio['host_response_time'].fillna(method='bfill')\n",
      "C:\\Users\\vbece\\AppData\\Local\\Temp\\ipykernel_10428\\1120293309.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cambio['host_response_time'] = cambio['host_response_time'].fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "#Rellena los NaN usando el valor anterior (Forward Fill)\n",
    "cambio['host_response_time'] = cambio['host_response_time'].fillna(method='ffill')\n",
    "#Rellena los NaN usando el valor posterior (Backward Fill)\n",
    "cambio['host_response_time'] = cambio['host_response_time'].fillna(method='bfill')\n",
    "\n",
    "#Verificamos de nuevo los valores nulos \n",
    "print('Número de valores nulos:',cambio['host_response_time'].isnull().sum())\n",
    "#Verificamos cambios\n",
    "print('Lista de valores únicos:',cambio['host_response_time'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef092ac6",
   "metadata": {},
   "source": [
    "Correlación Lógistica "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8272c6d3",
   "metadata": {},
   "source": [
    "VARIABLES ELEGIDAS\n",
    "Mexico_Limpio = 'host_is_superhost', 'accommodates', 'bathrooms', 'bedrooms', 'beds','room_type' \n",
    "Original_Mexico = 'host_response_time', 'host_verifications', 'instant_bookable', 'host_since' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "328c74a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'scrape_id', 'host_id', 'host_response_rate',\n",
       "       'host_acceptance_rate', 'host_is_superhost', 'host_listings_count',\n",
       "       'host_total_listings_count', 'latitude', 'longitude', 'accommodates',\n",
       "       'bathrooms', 'bedrooms', 'beds', 'price', 'minimum_nights',\n",
       "       'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights',\n",
       "       'minimum_maximum_nights', 'maximum_maximum_nights',\n",
       "       'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'availability_30',\n",
       "       'availability_60', 'availability_90', 'availability_365',\n",
       "       'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d',\n",
       "       'availability_eoy', 'number_of_reviews_ly', 'estimated_occupancy_l365d',\n",
       "       'estimated_revenue_l365d', 'review_scores_rating',\n",
       "       'review_scores_accuracy', 'review_scores_cleanliness',\n",
       "       'review_scores_checkin', 'review_scores_communication',\n",
       "       'review_scores_location', 'review_scores_value',\n",
       "       'calculated_host_listings_count',\n",
       "       'calculated_host_listings_count_entire_homes',\n",
       "       'calculated_host_listings_count_private_rooms',\n",
       "       'calculated_host_listings_count_shared_rooms', 'reviews_per_month',\n",
       "       'room_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limpio.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "468a62a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos copia de la base de datos original seleciconada a la base limpia\n",
    "limpio['host_response_time'] = cambio['host_response_time']\n",
    "limpio['host_verifications'] = cambio['host_verifications']\n",
    "limpio['instant_bookable'] = cambio['instant_bookable']\n",
    "limpio['host_since'] = cambio['host_since']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e0eb2a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión de la variables host_since:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Precisión del modelo: 0.01918949627572276\n",
      "Exactitud del modelo: 0.01918949627572276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vbece\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1784: UserWarning: Note that pos_label (set to 'Antes del 30/01/2023') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbece\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1784: UserWarning: Note that pos_label (set to 'Después del 30/01/2023') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidad del modelo: 0.01918949627572276\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= limpio[['estimated_occupancy_l365d', 'number_of_reviews_ltm']]\n",
    "Var_Dep= limpio['host_since']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None) \n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión de la variables host_since:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"micro\", pos_label=\"Antes del 30/01/2023\")\n",
    "print('Precisión del modelo:', precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:', exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"micro\", pos_label=\"Después del 30/01/2023\")\n",
    "print('Sensibilidad del modelo:', sensibilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d5dd3fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión de la variables host_response_time:\n",
      "[[   0  702]\n",
      " [   0 7219]]\n",
      "Precisión del modelo: 0.9113748264108067\n",
      "Exactitud del modelo: 0.9113748264108067\n",
      "Sensibilidad del modelo: 0.0\n",
      "---------------Aplicando Reponderación de las clases------------------\n",
      "Matriz de Confusión con Reponderación de clases:\n",
      "[[ 580  122]\n",
      " [3982 3237]]\n",
      "Precisión del modelo:\n",
      "0.9636796665674308\n",
      "Exactitud del modelo:\n",
      "0.4818836005554854\n",
      "Sensibilidad del modelo:\n",
      "0.8262108262108262\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= limpio[['number_of_reviews', 'review_scores_communication']]\n",
    "Var_Dep= limpio['host_response_time']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None) \n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión de la variables host_response_time:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Horas de Respuesta\")\n",
    "print('Precisión del modelo:', precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:', exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Días de Respuesta\")\n",
    "print('Sensibilidad del modelo:', sensibilidad)\n",
    "\n",
    "print('---------------Aplicando Reponderación de las clases------------------')\n",
    "\n",
    "#Reponderación de las clases\n",
    "algoritmo_Pond = LogisticRegression(class_weight='balanced')\n",
    "algoritmo_Pond.fit(X_train, y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred_pond = algoritmo_Pond.predict(X_test) \n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz_2 = confusion_matrix(y_test, y_pred_pond)\n",
    "print('Matriz de Confusión con Reponderación de clases:')\n",
    "print(matriz_2)\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred_pond, average=\"binary\", pos_label=\"Horas de Respuesta\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision) \n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred_pond)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred_pond, average=\"binary\", pos_label=\"Días de Respuesta\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c99838c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión de la variables host_verifications:\n",
      "[[7174    0]\n",
      " [ 747    0]]\n",
      "Precisión del modelo: 0.9056937255397046\n",
      "Exactitud del modelo: 0.9056937255397046\n",
      "Sensibilidad del modelo: 0.0\n",
      "---------------Aplicando Reponderación de las clases------------------\n",
      "Matriz de Confusión con Reponderación de clases:\n",
      "[[3072 4102]\n",
      " [ 207  540]]\n",
      "Precisión del modelo:\n",
      "0.9368709972552608\n",
      "Exactitud del modelo:\n",
      "0.4560030299204646\n",
      "Sensibilidad del modelo:\n",
      "0.7228915662650602\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= limpio[['review_scores_communication', 'number_of_reviews']]\n",
    "Var_Dep= limpio['host_verifications']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None) \n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión de la variables host_verifications:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Más de un método\")\n",
    "print('Precisión del modelo:', precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:', exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Un método\")\n",
    "print('Sensibilidad del modelo:', sensibilidad)\n",
    "\n",
    "\n",
    "print('---------------Aplicando Reponderación de las clases------------------')\n",
    "\n",
    "#Reponderación de las clases\n",
    "algoritmo_Pond = LogisticRegression(class_weight='balanced')\n",
    "algoritmo_Pond.fit(X_train, y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred_pond = algoritmo_Pond.predict(X_test) \n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz_2 = confusion_matrix(y_test, y_pred_pond)\n",
    "print('Matriz de Confusión con Reponderación de clases:')\n",
    "print(matriz_2)\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred_pond, average=\"binary\", pos_label=\"Más de un método\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision) \n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred_pond)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred_pond, average=\"binary\", pos_label=\"Un método\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "58861112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión de la variables instant_bookable:\n",
      "[[4059  556]\n",
      " [2467  839]]\n",
      "Precisión del modelo: 0.6014336917562724\n",
      "Exactitud del modelo: 0.6183562681479611\n",
      "Sensibilidad del modelo: 0.8795232936078007\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= limpio[['reviews_per_month', 'review_scores_value']]\n",
    "Var_Dep= limpio['instant_bookable']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None) \n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión de la variables instant_bookable:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Reserva Automática\")\n",
    "print('Precisión del modelo:', precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:', exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"No Reserva Automática\")\n",
    "print('Sensibilidad del modelo:', sensibilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c1843a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión de la variables room_type:\n",
      "[[4047 1159]\n",
      " [1435 1280]]\n",
      "Precisión del modelo: 0.7382342210871945\n",
      "Exactitud del modelo: 0.6725160964524681\n",
      "Sensibilidad del modelo: 0.4714548802946593\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= limpio[['estimated_revenue_l365d', 'number_of_reviews']]\n",
    "Var_Dep= limpio['room_type']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None) \n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión de la variables room_type:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Alojamiento Completo\")\n",
    "print('Precisión del modelo:', precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:', exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Alojamiento Parcial\")\n",
    "print('Sensibilidad del modelo:', sensibilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ba238b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión de la variables beds:\n",
      "[[6313  105]\n",
      " [1259  244]]\n",
      "Precisión del modelo: 0.833729529846804\n",
      "Exactitud del modelo: 0.8277995202625931\n",
      "Sensibilidad del modelo: 0.16234198270126413\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= limpio[['estimated_revenue_l365d', 'price']]\n",
    "Var_Dep= limpio['beds']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None) \n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión de la variables beds:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Dos o menos de dos camas\")\n",
    "print('Precisión del modelo:', precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:', exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Más de dos camas\")\n",
    "print('Sensibilidad del modelo:', sensibilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "89be6699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión de la variables bedrooms:\n",
      "[[6976  166]\n",
      " [ 573  206]]\n",
      "Precisión del modelo: 0.9240959067426149\n",
      "Exactitud del modelo: 0.9067036990279005\n",
      "Sensibilidad del modelo: 0.2644415917843389\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= limpio[['price', 'maximum_nights']]\n",
    "Var_Dep= limpio['bedrooms']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None) \n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión de la variables bedrooms:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Dos o menos de dos cuartos\")\n",
    "print('Precisión del modelo:', precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:', exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Más de dos cuartos\")\n",
    "print('Sensibilidad del modelo:', sensibilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7eea49c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión de la variables bathrooms:\n",
      "[[   0   63]\n",
      " [   0 7858]]\n",
      "Precisión del modelo: 0.992046458780457\n",
      "Exactitud del modelo: 0.992046458780457\n",
      "Sensibilidad del modelo: 0.0\n",
      "---------------Aplicando Reponderación de las clases------------------\n",
      "Matriz de Confusión con Reponderación de clases:\n",
      "[[  44   19]\n",
      " [4075 3783]]\n",
      "Precisión del modelo:\n",
      "0.9950026301946344\n",
      "Exactitud del modelo:\n",
      "0.48314606741573035\n",
      "Sensibilidad del modelo:\n",
      "0.6984126984126984\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= limpio[['price', 'availability_365']]\n",
    "Var_Dep= limpio['bathrooms']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None) \n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión de la variables bathrooms:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Uno o más baños completos\")\n",
    "print('Precisión del modelo:', precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:', exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label='Menos de un baño completo')\n",
    "print('Sensibilidad del modelo:', sensibilidad)\n",
    "\n",
    "print('---------------Aplicando Reponderación de las clases------------------')\n",
    "\n",
    "#Reponderación de las clases\n",
    "algoritmo_Pond = LogisticRegression(class_weight='balanced')\n",
    "algoritmo_Pond.fit(X_train, y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred_pond = algoritmo_Pond.predict(X_test) \n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz_2 = confusion_matrix(y_test, y_pred_pond)\n",
    "print('Matriz de Confusión con Reponderación de clases:')\n",
    "print(matriz_2)\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred_pond, average=\"binary\", pos_label=\"Uno o más baños completos\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision) \n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred_pond)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred_pond, average=\"binary\", pos_label=\"Menos de un baño completo\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "97d0c194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión de la variables accomodates:\n",
      "[[2092 1726]\n",
      " [1142 2961]]\n",
      "Precisión del modelo: 0.6317473863878814\n",
      "Exactitud del modelo: 0.6379245044817573\n",
      "Sensibilidad del modelo: 0.5479308538501834\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= limpio[['price', 'availability_30']]\n",
    "Var_Dep= limpio['accommodates']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None) \n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión de la variables accomodates:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Alojamiento para Parejas/Individual\")\n",
    "print('Precisión del modelo:', precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:', exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Alojamiento para Familias/Grupos\")\n",
    "print('Sensibilidad del modelo:', sensibilidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0925f643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión de la variables host_is_superhost:\n",
      "[[4113  763]\n",
      " [1888 1157]]\n",
      "Precisión del modelo: 0.6853857690384936\n",
      "Exactitud del modelo: 0.6653200353490721\n",
      "Sensibilidad del modelo: 0.37996715927750413\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= limpio[['host_response_rate', 'reviews_per_month' ]]\n",
    "Var_Dep= limpio['host_is_superhost']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None) \n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión de la variables host_is_superhost:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Es Superhost\")\n",
    "print('Precisión del modelo:', precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:', exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"No es Superhost\")\n",
    "print('Sensibilidad del modelo:', sensibilidad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
